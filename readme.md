# ğŸŒ± Deep Learningâ€“Based Laser Weed Removal System
## Sustainable Agricultural & Forest Automation Rover

---

## ğŸ“Œ Project Overview

This project presents the design, fabrication, and implementation of a deep learningâ€“based agricultural rover capable of:

- ğŸ”¥ **Laser-based selective weed removal** (non-chemical)
- ğŸŒ¾ **Automated seed dispensing**
- ğŸ’§ **Targeted fertilizer spraying**
- ğŸ¤– **Real-time weed detection** using YOLOv11 deep learning

The system aims to provide a **cost-effective, scalable, and eco-friendly solution** for small and medium-scale farms, reducing labor dependency and chemical herbicide usage while improving crop yield and sustainability.

![Rover](./media/rover.jpg)

---

## ğŸ¯ Key Objectives

âœ… Implement real-time weed detection and classification using deep learning

âœ… Enable precision laser weed elimination without harming crops

âœ… Integrate automated seed sowing and fertilizer spraying

âœ… Reduce environmental impact and operational costs

âœ… Support Sustainable Development Goals **(SDG 2 & SDG 12)**

---

## ğŸ§  System Architecture

### Hardware Architecture

| Component | Specifications |
|-----------|---|
| **Raspberry Pi 4** | 4GB RAM - Runs YOLOv11 model, processes camera feed, hosts Flask backend |
| **ESP32 Microcontroller** | Handles low-level control, communicates via REST APIs over Wi-Fi |
| **Camera Module** | Real-time video capture for weed detection |
| **Laser Module** | Pan-tilt mechanism (servo-driven) for precise weed targeting |
| **DC Motors** | Rover movement control |
| **Seed Dispenser** | Servo-controlled hopper for automated seed sowing |
| **Fertilizer System** | Pump and spray nozzle for targeted fertilizer application |

![Motor Actuator](./media/motor%20actuator.jpg)

### Software Stack

- **Backend**: Flask (Python) on Raspberry Pi
- **Deep Learning**: YOLOv11 (Nano version)
- **Frontend**: React Native + Expo (Mobile App)
- **Communication**: REST APIs, HTTP/WebSocket
- **Microcontroller**: Arduino IDE (ESP32)

---

## ğŸ§ª Deep Learning Model

### Model Details

**YOLOv11n (Nano version)**
- Optimized for real-time inference on embedded devices
- Multi-scale object detection
- SPFF (Spatial Pyramid Pooling Fast)
- C2PSA spatial attention mechanism
- High FPS with low computational cost

![Weed Detection](./media/weed.jpg)

### Weed Classes (16 Total)

The model detects and classifies the following common agricultural weeds:

- Palmer Amaranth
- Carpetweed
- Crabgrass
- Morning Glory
- Nutsedge
- Ragweed
- Waterhemp
- (and 9 more varieties)

### Performance Metrics

| Metric | Value |
|--------|-------|
| **mAP@0.5** | ~91% |
| **FPS** | ~24 |
| **Precision** | >80% |
| **Recall** | ~74% |
| **Mask mAP@0.5** | ~79% |

![Laser System](./media/laser.png)

---

## ğŸ“‚ Project File Structure

```
agribot/
â”œâ”€â”€ README.md                          # Project documentation
â”œâ”€â”€ app.json                           # Expo app configuration
â”œâ”€â”€ package.json                       # Node.js dependencies
â”œâ”€â”€ tsconfig.json                      # TypeScript configuration
â”œâ”€â”€ tailwind.config.js                 # Tailwind CSS configuration
â”œâ”€â”€ nativewind-env.d.ts               # NativeWind type definitions
â”œâ”€â”€ metro.config.js                    # Metro bundler configuration
â”œâ”€â”€ babel.config.js                    # Babel transpiler configuration
â”œâ”€â”€ eslint.config.js                   # ESLint configuration
â”œâ”€â”€ axiosconfig.js                     # Axios HTTP client configuration
â”œâ”€â”€ eas.json                           # Expo Application Services config
â”œâ”€â”€ expo-env.d.ts                      # Expo environment types
â”œâ”€â”€ global.css                         # Global stylesheet
â”‚
â”œâ”€â”€ app/                               # React Native app directory
â”‚   â”œâ”€â”€ _layout.tsx                    # App layout/navigation
â”‚   â””â”€â”€ index.tsx                      # Home screen
â”‚
â”œâ”€â”€ assets/                            # Static assets
â”‚   â”œâ”€â”€ fonts/
â”‚   â”‚   â””â”€â”€ SpaceMono-Regular.ttf      # Custom font
â”‚   â””â”€â”€ images/
â”‚       â”œâ”€â”€ adaptive-icon.png
â”‚       â”œâ”€â”€ favicon.png
â”‚       â”œâ”€â”€ icon.png
â”‚       â”œâ”€â”€ iconagri.png              # Agriculture-themed icon
â”‚       â”œâ”€â”€ partial-react-logo.png
â”‚       â”œâ”€â”€ react-logo.png
â”‚       â”œâ”€â”€ react-logo@2x.png
â”‚       â”œâ”€â”€ react-logo@3x.png
â”‚       â””â”€â”€ splash-icon.png
â”‚
â””â”€â”€ media/                             # Project media resources
    â”œâ”€â”€ rover.jpg                      # Rover hardware image
    â”œâ”€â”€ laser.png                      # Laser system diagram
    â”œâ”€â”€ motor_actuator.jpg             # Motor actuation system
    â””â”€â”€ weed.jpg                       # Weed detection sample
```

---

## ğŸš€ Getting Started

### Prerequisites

- **Node.js** (v16+)
- **npm** or **yarn**
- **Python 3.8+** (for Raspberry Pi backend)
- **Expo CLI**

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/agribot.git
   cd agribot
   ```

2. **Install dependencies**
   ```bash
   npm install
   ```

3. **Configure environment variables**
   - Update `axiosconfig.js` with your Raspberry Pi IP address
   - Set the appropriate API endpoints for Flask backend

4. **Run the app**
   ```bash
   npx expo start
   ```

---

## ğŸ”Œ API Communication

### HTTP Configuration

To allow HTTP requests in the Expo app (for development with local servers):

**In `app.json` (iOS):**
```json
{
  "ios": {
    "infoPlist": {
      "NSAppTransportSecurity": {
        "NSAllowsArbitraryLoads": true
      }
    }
  }
}
```

**In `app.json` (Android):**
```json
{
  "android": {
    "usesCleartextTraffic": true
  }
}
```

**Using Axios (in `axiosconfig.js`):**
```javascript
import axios from 'axios';

const instance = axios.create({
  baseURL: 'http://192.168.1.100:5000', // Replace with Raspberry Pi IP
  timeout: 10000,
});

export default instance;
```

---

## ğŸ¨ Features

### 1. Real-time Weed Detection
- Live camera feed processing
- YOLOv11-based classification
- High accuracy detection with minimal latency

### 2. Precision Laser Control
- Servo-driven pan-tilt mechanism
- Accurate targeting of detected weeds
- Safe operation within crop areas

### 3. Automated Seed Dispensing
- Servo-controlled hopper
- Programmable seed distribution
- Variable rate application

### 4. Smart Fertilizer Spraying
- Targeted spray application
- Integration with weed detection
- Adjustable spray patterns

### 5. Mobile Control Interface
- React Native frontend
- Real-time monitoring dashboard
- Manual override capabilities

---

## ğŸ“Š Workflow

```
Camera Input
    â†“
YOLOv11 Detection
    â†“
Classification & Localization
    â†“
Decision Engine
    â†“
â”œâ”€â†’ Laser Targeting & Firing
â”œâ”€â†’ Seed Dispensing
â””â”€â†’ Fertilizer Spraying
    â†“
Rover Movement & Navigation
    â†“
Database Logging & Analytics
```

---

## ğŸ” Security & Safety

- âœ… Non-chemical weed removal (laser-based)
- âœ… Crop-safe detection algorithm
- âœ… Emergency stop mechanisms
- âœ… Secure communication protocols (HTTPS for production)
- âœ… Authentication for mobile app access

---

## ğŸ“ˆ Performance & Scalability

- **Real-time Processing**: 24 FPS on Raspberry Pi 4
- **Energy Efficient**: Optimized for extended field operations
- **Scalable Design**: Can be deployed on multiple rovers
- **Data Logging**: Records all operations for analytics

---

## ğŸŒ Sustainability Impact

This system directly contributes to:

- **SDG 2 (Zero Hunger)**: Improved crop yields through precision agriculture
- **SDG 12 (Responsible Consumption)**: Reduced chemical herbicide usage
- **Environmental Protection**: Lower carbon footprint, reduced water contamination
- **Economic Benefits**: Cost reduction in labor and chemical inputs

---

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“ License

This project is licensed under the **MIT License** - see the LICENSE file for details.

---

## ğŸ“§ Contact & Support

- **Project Lead**: [Your Name]
- **Email**: [your.email@example.com]
- **GitHub Issues**: [Report bugs and request features](https://github.com/yourusername/agribot/issues)

---

## ğŸ™ Acknowledgments

- YOLOv11 by Ultralytics
- Expo & React Native community
- Raspberry Pi Foundation
- Open-source contributors

---

**Last Updated**: December 29, 2025

*"Sustainable agriculture powered by AI and automation"* ğŸŒ±ğŸ¤–
